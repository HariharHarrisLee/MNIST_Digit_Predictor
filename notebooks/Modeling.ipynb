{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognition - Model Development\n",
    "\n",
    "This notebook demonstrates the development and comparison of MLP and CNN models for MNIST digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape for CNN (add channel dimension)\n",
    "x_train_cnn = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test_cnn = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Training data shape (MLP): {x_train.shape}\")\n",
    "print(f\"Training data shape (CNN): {x_train_cnn.shape}\")\n",
    "print(f\"Training labels shape: {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model():\n",
    "    \"\"\"Create MLP (Multi-Layer Perceptron) model\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_cnn_model():\n",
    "    \"\"\"Create CNN (Convolutional Neural Network) model\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "mlp_model = create_mlp_model()\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "# Display model summaries\n",
    "print(\"MLP Model Architecture:\")\n",
    "mlp_model.summary()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"CNN Model Architecture:\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Train MLP model\n",
    "print(\"Training MLP Model...\")\n",
    "start_time = time.time()\n",
    "mlp_history = mlp_model.fit(\n",
    "    x_train, y_train_cat,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "mlp_training_time = time.time() - start_time\n",
    "print(f\"MLP Training completed in {mlp_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN model\n",
    "print(\"Training CNN Model...\")\n",
    "start_time = time.time()\n",
    "cnn_history = cnn_model.fit(\n",
    "    x_train_cnn, y_train_cat,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "cnn_training_time = time.time() - start_time\n",
    "print(f\"CNN Training completed in {cnn_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "mlp_test_loss, mlp_test_acc = mlp_model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(x_test_cnn, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"MLP Test Accuracy: {mlp_test_acc:.4f}\")\n",
    "print(f\"CNN Test Accuracy: {cnn_test_acc:.4f}\")\n",
    "print(f\"MLP Training Time: {mlp_training_time:.2f}s\")\n",
    "print(f\"CNN Training Time: {cnn_training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy plots\n",
    "axes[0, 0].plot(mlp_history.history['accuracy'], label='MLP Train', color='blue')\n",
    "axes[0, 0].plot(mlp_history.history['val_accuracy'], label='MLP Val', color='blue', linestyle='--')\n",
    "axes[0, 0].set_title('MLP Model Accuracy')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(cnn_history.history['accuracy'], label='CNN Train', color='red')\n",
    "axes[0, 1].plot(cnn_history.history['val_accuracy'], label='CNN Val', color='red', linestyle='--')\n",
    "axes[0, 1].set_title('CNN Model Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plots\n",
    "axes[1, 0].plot(mlp_history.history['loss'], label='MLP Train', color='blue')\n",
    "axes[1, 0].plot(mlp_history.history['val_loss'], label='MLP Val', color='blue', linestyle='--')\n",
    "axes[1, 0].set_title('MLP Model Loss')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(cnn_history.history['loss'], label='CNN Train', color='red')\n",
    "axes[1, 1].plot(cnn_history.history['val_loss'], label='CNN Val', color='red', linestyle='--')\n",
    "axes[1, 1].set_title('CNN Model Loss')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "mlp_pred = np.argmax(mlp_model.predict(x_test, verbose=0), axis=1)\n",
    "cnn_pred = np.argmax(cnn_model.predict(x_test_cnn, verbose=0), axis=1)\n",
    "\n",
    "# Create confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# MLP Confusion Matrix\n",
    "cm_mlp = confusion_matrix(y_test, mlp_pred)\n",
    "sns.heatmap(cm_mlp, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "ax1.set_title('MLP Confusion Matrix')\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('Actual')\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cm_cnn = confusion_matrix(y_test, cnn_pred)\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Reds', ax=ax2)\n",
    "ax2.set_title('CNN Confusion Matrix')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "print(\"MLP Classification Report:\")\n",
    "print(classification_report(y_test, mlp_pred))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "mlp_model.save('../models/mlp_baseline.h5')\n",
    "cnn_model.save('../models/mnist_cnn.h5')\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Implementation of MLP and CNN architectures\n",
    "2. Training both models on MNIST dataset\n",
    "3. Performance comparison between architectures\n",
    "4. Model persistence for later use\n",
    "\n",
    "The CNN typically achieves higher accuracy due to its ability to capture spatial features in images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}